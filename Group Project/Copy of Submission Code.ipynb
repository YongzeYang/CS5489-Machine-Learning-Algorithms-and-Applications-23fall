{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "919ab277",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-08T02:44:18.918062Z",
     "iopub.status.busy": "2023-12-08T02:44:18.917590Z",
     "iopub.status.idle": "2023-12-08T02:44:22.541638Z",
     "shell.execute_reply": "2023-12-08T02:44:22.540498Z"
    },
    "papermill": {
     "duration": 3.632795,
     "end_time": "2023-12-08T02:44:22.544424",
     "exception": false,
     "start_time": "2023-12-08T02:44:18.911629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib_inline   # setup output image format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "random.seed(100)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from joblib import dump, load\n",
    "%matplotlib inline\n",
    "import matplotlib_inline   # setup output image format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import os\n",
    "import zipfile\n",
    "import fnmatch\n",
    "random.seed(100)\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import skimage.color\n",
    "import skimage.exposure\n",
    "import skimage.io\n",
    "import skimage.util\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81ce772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:44:22.555908Z",
     "iopub.status.busy": "2023-12-08T02:44:22.555328Z",
     "iopub.status.idle": "2023-12-08T02:44:22.560035Z",
     "shell.execute_reply": "2023-12-08T02:44:22.558884Z"
    },
    "papermill": {
     "duration": 0.012283,
     "end_time": "2023-12-08T02:44:22.562520",
     "exception": false,
     "start_time": "2023-12-08T02:44:22.550237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls /kaggle/input/nltkdata/nltk_data/\n",
    "# !mkdir /usr/local/lib/nltk_data\n",
    "# !mkdir /usr/local/lib/nltk_data/corpora\n",
    "# !cp -r /kaggle/input/nltkdata/nltk_data/* /usr/local/lib/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b262e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:44:22.572016Z",
     "iopub.status.busy": "2023-12-08T02:44:22.571635Z",
     "iopub.status.idle": "2023-12-08T02:44:25.713017Z",
     "shell.execute_reply": "2023-12-08T02:44:25.711841Z"
    },
    "papermill": {
     "duration": 3.149194,
     "end_time": "2023-12-08T02:44:25.715682",
     "exception": false,
     "start_time": "2023-12-08T02:44:22.566488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "concat_dataset = '/kaggle/input/daigt-one-place-all-data/concatenated.csv'\n",
    "test_csv_path = '/kaggle/input/llm-detect-ai-generated-text/test_essays.csv'\n",
    "\n",
    "train_dataset_df = pd.read_csv(concat_dataset)\n",
    "test_dataset_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "train_text_list = train_dataset_df['text'].tolist()\n",
    "test_text_list = test_dataset_df['text'].tolist()\n",
    "\n",
    "train_y = train_dataset_df['generated'].values\n",
    "\n",
    "train_id = train_dataset_df['id'].tolist()\n",
    "test_id = test_dataset_df['id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6640a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:44:25.725555Z",
     "iopub.status.busy": "2023-12-08T02:44:25.725111Z",
     "iopub.status.idle": "2023-12-08T02:45:14.642793Z",
     "shell.execute_reply": "2023-12-08T02:45:14.641983Z"
    },
    "papermill": {
     "duration": 48.925253,
     "end_time": "2023-12-08T02:45:14.644992",
     "exception": false,
     "start_time": "2023-12-08T02:44:25.719739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer feature representing finished.\n",
      "TF-IDF feature representing calculated.\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=22000)\n",
    "train_features = vectorizer.fit_transform(train_text_list)\n",
    "test_features = vectorizer.transform(test_text_list)\n",
    "print('CountVectorizer feature representing finished.')\n",
    "\n",
    "# Calculate TF-IDF value\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "train_X = tf_trans.fit_transform(train_features)\n",
    "test_X = tf_trans.transform(test_features)\n",
    "print('TF-IDF feature representing calculated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a76aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:45:14.654565Z",
     "iopub.status.busy": "2023-12-08T02:45:14.654021Z",
     "iopub.status.idle": "2023-12-08T02:45:14.660146Z",
     "shell.execute_reply": "2023-12-08T02:45:14.659128Z"
    },
    "papermill": {
     "duration": 0.013606,
     "end_time": "2023-12-08T02:45:14.662493",
     "exception": false,
     "start_time": "2023-12-08T02:45:14.648887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from nltk import word_tokenize, PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "# import re\n",
    "# import nltk\n",
    "\n",
    "# # Init stop words and stemmer\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def preprocess_list(str):\n",
    "#     \"\"\"\n",
    "#     Preprocess text data by removing non-alphanumeric characters & stop word and lemmatizing\n",
    "\n",
    "#     :param str: input string\n",
    "#     :return: preprocessed word list\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Remove non-alphanumeric characters\n",
    "#     string_only_alphanumeric = re.sub(r'[^a-zA-Z0-9]', ' ', str)\n",
    "#     # Tokenize the string into individual words\n",
    "#     words = word_tokenize(string_only_alphanumeric)\n",
    "#     new_str = []\n",
    "\n",
    "#     for word in words:\n",
    "#         if not word.isdigit():\n",
    "#             # Remove stop word\n",
    "#             if word not in stop_words:\n",
    "#                 # lemmatization and convert to lower case\n",
    "#                 stemmed_word = lemmatizer.lemmatize(word)\n",
    "#                 lower_word = stemmed_word.lower()\n",
    "#                 new_str.append(lower_word)\n",
    "#     return new_str\n",
    "\n",
    "# test = 'En chikku nange bakra msg kalstiya..then had tea/coffee?'\n",
    "# print(preprocess_list(test))\n",
    "\n",
    "# train_word_list = [preprocess_list(s) for s in train_text_list]\n",
    "# test_word_list = [preprocess_list(s) for s in test_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c86517f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:45:14.672612Z",
     "iopub.status.busy": "2023-12-08T02:45:14.672166Z",
     "iopub.status.idle": "2023-12-08T02:45:14.677222Z",
     "shell.execute_reply": "2023-12-08T02:45:14.676113Z"
    },
    "papermill": {
     "duration": 0.012875,
     "end_time": "2023-12-08T02:45:14.679313",
     "exception": false,
     "start_time": "2023-12-08T02:45:14.666438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import ParameterGrid\n",
    "# from gensim.models import Word2Vec\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# model_w2v = Word2Vec(train_word_list, min_count= 1, vector_size= 500, window= 10)\n",
    "\n",
    "# def generate_w2v(word_list):\n",
    "#     X = []\n",
    "#     # Build word2Vec features\n",
    "#     for sentence in word_list:\n",
    "#         sentence_vector = []\n",
    "#         for word in sentence:\n",
    "#             # if the word is in the wv list\n",
    "#             if word in model_w2v.wv:\n",
    "#                 word_vec = model_w2v.wv[word]\n",
    "#                 sentence_vector.append(word_vec)\n",
    "#         if len(sentence_vector) > 0:\n",
    "#             # can be presented as a vector\n",
    "#             average_vec = np.mean(sentence_vector,axis=0)\n",
    "#         else:\n",
    "#             # vector of 0 as default\n",
    "#             average_vec = np.zeros(500)\n",
    "#         X.append(average_vec)\n",
    "#     return X\n",
    "\n",
    "# train_w2v = generate_w2v(train_word_list)\n",
    "# test_w2v = generate_w2v(test_word_list)\n",
    "# set_w2v = [train_w2v, test_w2v]\n",
    "\n",
    "# print(shape(train_w2v))\n",
    "# print(shape(test_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0ae17",
   "metadata": {
    "papermill": {
     "duration": 0.00357,
     "end_time": "2023-12-08T02:45:14.686751",
     "exception": false,
     "start_time": "2023-12-08T02:45:14.683181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac3dea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:45:14.696090Z",
     "iopub.status.busy": "2023-12-08T02:45:14.695675Z",
     "iopub.status.idle": "2023-12-08T02:45:14.701910Z",
     "shell.execute_reply": "2023-12-08T02:45:14.700823Z"
    },
    "papermill": {
     "duration": 0.013728,
     "end_time": "2023-12-08T02:45:14.704267",
     "exception": false,
     "start_time": "2023-12-08T02:45:14.690539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Count Vectorizer\n",
    "# vectorizer = CountVectorizer(stop_words='english', max_features=3150)\n",
    "# train_features = vectorizer.fit_transform(train_txt_preprocessed)\n",
    "# test_features = vectorizer.transform(test_txt_preprocessed)\n",
    "# print('CountVectorizer feature representing finished.')\n",
    "\n",
    "# # Calculate TF-IDF value\n",
    "# tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "# train_X = tf_trans.fit_transform(train_features)\n",
    "# test_X = tf_trans.transform(test_features)\n",
    "# print('TF-IDF feature representing calculated.')\n",
    "\n",
    "# train_X = train_w2v\n",
    "# test_X = test_w2v\n",
    "\n",
    "\n",
    "\n",
    "# clf_rf = ensemble.RandomForestClassifier(random_state=4487,max_depth=8,max_features=0.14000883833708455,n_estimators=1000)\n",
    "\n",
    "# clf_ada = ensemble.AdaBoostClassifier(random_state=4487,learning_rate=0.03162277660168379, n_estimators=500)\n",
    "\n",
    "# clf_xgb = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric='logloss', random_state=4487, use_label_encoder=False,gamma= 0.4257366859173304, learning_rate= 0.35526774997253563, max_depth= 4, n_estimators= 734, subsample= 0.6262634075987297)\n",
    "\n",
    "# clf_gb = ensemble.GradientBoostingClassifier(n_estimators= 100, learning_rate = 1.0)\n",
    "\n",
    "# clf_knn = neighbors.KNeighborsClassifier(n_neighbors= 3)\n",
    "\n",
    "# clf_svm_poly = svm.SVC(C= 3.1622776601683795, degree= 2, kernel='poly',probability=True)\n",
    "\n",
    "# clf_nb = naive_bayes.BernoulliNB(alpha=1e-10)\n",
    "\n",
    "\n",
    "# clf_list = [('rf', clf_rf), \n",
    "#             ('ada', clf_ada), \n",
    "#             ('xbg', clf_xgb), \n",
    "#             ('gb', clf_gb), \n",
    "#             ('knn', clf_knn), \n",
    "#             ('svm_poly', clf_svm_poly),\n",
    "#             ('nb', clf_nb)]\n",
    "\n",
    "# clf_list = [('xbg', clf_xgb), \n",
    "#             ('knn', clf_knn), \n",
    "#             ('svm_poly', clf_svm_poly),\n",
    "#             ('nb', clf_nb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61135d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:45:14.713917Z",
     "iopub.status.busy": "2023-12-08T02:45:14.713528Z",
     "iopub.status.idle": "2023-12-08T02:45:15.043396Z",
     "shell.execute_reply": "2023-12-08T02:45:15.042151Z"
    },
    "papermill": {
     "duration": 0.337764,
     "end_time": "2023-12-08T02:45:15.046042",
     "exception": false,
     "start_time": "2023-12-08T02:45:14.708278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained.\n",
      "Predicting finished\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "# model = ensemble.VotingClassifier(estimators=clf_list, voting='soft')\n",
    "model = naive_bayes.BernoulliNB(alpha=1e-10)\n",
    "model.fit(train_X,train_y)\n",
    "print('Trained.')\n",
    "\n",
    "y_pred = model.predict_proba(test_X)\n",
    "print('Predicting finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d81c4e2",
   "metadata": {
    "papermill": {
     "duration": 0.003943,
     "end_time": "2023-12-08T02:45:15.054082",
     "exception": false,
     "start_time": "2023-12-08T02:45:15.050139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a3b5f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:45:15.065602Z",
     "iopub.status.busy": "2023-12-08T02:45:15.065175Z",
     "iopub.status.idle": "2023-12-08T02:45:15.074975Z",
     "shell.execute_reply": "2023-12-08T02:45:15.073832Z"
    },
    "papermill": {
     "duration": 0.01827,
     "end_time": "2023-12-08T02:45:15.077427",
     "exception": false,
     "start_time": "2023-12-08T02:45:15.059157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({\n",
    "    'id': test_id,\n",
    "    'generated': y_pred[:, 1]\n",
    "})\n",
    "\n",
    "\n",
    "output_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d586379f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T02:45:15.087147Z",
     "iopub.status.busy": "2023-12-08T02:45:15.086769Z",
     "iopub.status.idle": "2023-12-08T02:45:15.092156Z",
     "shell.execute_reply": "2023-12-08T02:45:15.091026Z"
    },
    "papermill": {
     "duration": 0.013023,
     "end_time": "2023-12-08T02:45:15.094572",
     "exception": false,
     "start_time": "2023-12-08T02:45:15.081549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, confusion_matrix, f1_score, precision_score\n",
    "\n",
    "# predY = model.predict(test_X)\n",
    "# predY_proba = y_pred\n",
    "\n",
    "# # Calculate metrics data\n",
    "# accuracy = accuracy_score(testY, predY)\n",
    "# auc = roc_auc_score(testY, predY_proba[:, 1])\n",
    "# f1 = f1_score(testY, predY)\n",
    "# precision = precision_score(testY, predY)\n",
    "\n",
    "# tn, fp, fn, tp = confusion_matrix(testY, predY).ravel()\n",
    "# sensitivity = tp / (tp + fn)\n",
    "# specificity = tn / (tn + fp)\n",
    "\n",
    "# metrics_data.append([name, accuracy, auc, f1, precision, sensitivity, specificity])\n",
    "\n",
    "# # Show metrics data\n",
    "# print(f\"Result for Voting Classifier:\")\n",
    "# print(\"    Accuracy: \", accuracy)\n",
    "# print(\"    AUC: \", auc)\n",
    "# print(\"    F1 Score: \", f1)\n",
    "# print(\"    Precision: \", precision)\n",
    "# print(\"    Sensitivity: \", sensitivity)\n",
    "# print(\"    Specificity: \", specificity)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 4101275,
     "sourceId": 7112464,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4125480,
     "sourceId": 7146480,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 60.664281,
   "end_time": "2023-12-08T02:45:16.121487",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-08T02:44:15.457206",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
